{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:22:42.556883Z",
     "start_time": "2025-06-30T13:22:41.886647Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "ebb3c85a755510f9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:22:43.667877Z",
     "start_time": "2025-06-30T13:22:43.621317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cve_test_df = pd.read_csv(\"nasa_test.csv\")\n",
    "cve_test_df.info()"
   ],
   "id": "1421188b2005849e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2437 entries, 0 to 2436\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   repo    1262 non-null   object\n",
      " 1   func    2437 non-null   object\n",
      " 2   label   2437 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 57.2+ KB\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:25:47.229344Z",
     "start_time": "2025-06-30T13:25:47.218838Z"
    }
   },
   "cell_type": "code",
   "source": "print(cve_test_df['label'].value_counts())\n",
   "id": "9149c3d4b36f2996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    1262\n",
      "0    1175\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T13:28:49.904676Z",
     "start_time": "2025-06-30T13:28:32.261822Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== Load Test Data ======\n",
    "df = pd.read_csv(\"nasa_test.csv\")\n",
    "\n",
    "\n",
    "# Keep only binary labels (0 and 1)\n",
    "df = df[df[\"label\"].isin([0, 1])].dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "# ====== Load Model ======\n",
    "model_path = \"./codebert_trainFUNC_testFUNC_saved\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")  # tokenizer wasn't saved\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== Preprocess Test Set ======\n",
    "test_ds = Dataset.from_pandas(df)\n",
    "test_ds = test_ds.map(lambda batch: tokenizer([\"FUNC: \" + x for x in batch[\"func\"]],\n",
    "                                              truncation=True, padding='max_length', max_length=256), batched=True)\n",
    "test_ds = test_ds.rename_column(\"label\", \"labels\")\n",
    "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# ====== Define Metrics ======\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    except:\n",
    "        tn = fp = fn = tp = 0  # fallback for edge cases\n",
    "\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\": matthews_corrcoef(labels, preds),\n",
    "        \"kappa\": cohen_kappa_score(labels, preds),\n",
    "        \"mse\": mean_squared_error(labels, preds),\n",
    "        \"mae\": mean_absolute_error(labels, preds),\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "# ====== Run Evaluation ======\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=test_ds)\n",
    "\n",
    "# ====== Print Metrics ======\n",
    "print(\"\\n=== Evaluation on Devign Test Dataset ===\")\n",
    "for k, v in metrics.items():\n",
    "    if k.startswith(\"eval_\"):\n",
    "        print(f\"{k[5:]:<12}: {v:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user01\\PycharmProjects\\fol\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 2437/2437 [00:00<00:00, 5325.46 examples/s]\n",
      "C:\\Users\\user01\\PycharmProjects\\fol\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='305' max='305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [305/305 00:16]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Devign Test Dataset ===\n",
      "loss        : 2.9406\n",
      "accuracy    : 0.2556\n",
      "precision   : 0.3465\n",
      "recall      : 0.4937\n",
      "specificity : 0.0000\n",
      "fpr         : 1.0000\n",
      "f1          : 0.4072\n",
      "mcc         : -0.5752\n",
      "kappa       : -0.5144\n",
      "mse         : 0.7444\n",
      "mae         : 0.7444\n",
      "auc         : 0.0799\n",
      "runtime     : 16.1377\n",
      "samples_per_second: 151.0130\n",
      "steps_per_second: 18.9000\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:29:46.833777Z",
     "start_time": "2025-06-30T13:29:28.167592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== Load Test Data ======\n",
    "df = pd.read_csv(\"nasa_test.csv\")\n",
    "\n",
    "\n",
    "# Keep only binary labels (0 and 1)\n",
    "df = df[df[\"label\"].isin([0, 1])].dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "# ====== Load Model ======\n",
    "model_path = \"./graphcodebert_trainFUNC_testFUNC_saved\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")  # tokenizer wasn't saved\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== Preprocess Test Set ======\n",
    "test_ds = Dataset.from_pandas(df)\n",
    "test_ds = test_ds.map(lambda batch: tokenizer([\"FUNC: \" + x for x in batch[\"func\"]],\n",
    "                                              truncation=True, padding='max_length', max_length=256), batched=True)\n",
    "test_ds = test_ds.rename_column(\"label\", \"labels\")\n",
    "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# ====== Define Metrics ======\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    except:\n",
    "        tn = fp = fn = tp = 0  # fallback for edge cases\n",
    "\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\": matthews_corrcoef(labels, preds),\n",
    "        \"kappa\": cohen_kappa_score(labels, preds),\n",
    "        \"mse\": mean_squared_error(labels, preds),\n",
    "        \"mae\": mean_absolute_error(labels, preds),\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "# ====== Run Evaluation ======\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=test_ds)\n",
    "\n",
    "# ====== Print Metrics ======\n",
    "print(\"\\n=== Evaluation on Devign Test Dataset ===\")\n",
    "for k, v in metrics.items():\n",
    "    if k.startswith(\"eval_\"):\n",
    "        print(f\"{k[5:]:<12}: {v:.4f}\")\n"
   ],
   "id": "e62ff01c661320c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user01\\PycharmProjects\\fol\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 2437/2437 [00:00<00:00, 3905.77 examples/s]\n",
      "C:\\Users\\user01\\PycharmProjects\\fol\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='305' max='305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [305/305 00:16]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Devign Test Dataset ===\n",
      "loss        : 4.0614\n",
      "accuracy    : 0.2302\n",
      "precision   : 0.3232\n",
      "recall      : 0.4445\n",
      "specificity : 0.0000\n",
      "fpr         : 1.0000\n",
      "f1          : 0.3742\n",
      "mcc         : -0.6132\n",
      "kappa       : -0.5633\n",
      "mse         : 0.7698\n",
      "mae         : 0.7698\n",
      "auc         : 0.0751\n",
      "runtime     : 16.4403\n",
      "samples_per_second: 148.2330\n",
      "steps_per_second: 18.5520\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:30:37.625310Z",
     "start_time": "2025-06-30T13:30:19.862406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== Load Test Data ======\n",
    "df = pd.read_csv(\"nasa_test.csv\")\n",
    "\n",
    "\n",
    "# Keep only binary labels (0 and 1)\n",
    "df = df[df[\"label\"].isin([0, 1])].dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "# ====== Load Model ======\n",
    "model_path = \"./unixcoder_trainFUNC_testFUNC_saved\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unixcoder-base\")  # tokenizer wasn't saved\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== Preprocess Test Set ======\n",
    "test_ds = Dataset.from_pandas(df)\n",
    "test_ds = test_ds.map(lambda batch: tokenizer([\"FUNC: \" + x for x in batch[\"func\"]],\n",
    "                                              truncation=True, padding='max_length', max_length=256), batched=True)\n",
    "test_ds = test_ds.rename_column(\"label\", \"labels\")\n",
    "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# ====== Define Metrics ======\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    except:\n",
    "        tn = fp = fn = tp = 0  # fallback for edge cases\n",
    "\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\": fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\": matthews_corrcoef(labels, preds),\n",
    "        \"kappa\": cohen_kappa_score(labels, preds),\n",
    "        \"mse\": mean_squared_error(labels, preds),\n",
    "        \"mae\": mean_absolute_error(labels, preds),\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "# ====== Run Evaluation ======\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=test_ds)\n",
    "\n",
    "# ====== Print Metrics ======\n",
    "print(\"\\n=== Evaluation on Devign Test Dataset ===\")\n",
    "for k, v in metrics.items():\n",
    "    if k.startswith(\"eval_\"):\n",
    "        print(f\"{k[5:]:<12}: {v:.4f}\")\n"
   ],
   "id": "1125e200a51b0c31",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user01\\PycharmProjects\\fol\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 2437/2437 [00:00<00:00, 5255.85 examples/s]\n",
      "C:\\Users\\user01\\PycharmProjects\\fol\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='305' max='305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [305/305 00:15]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Devign Test Dataset ===\n",
      "loss        : 0.9260\n",
      "accuracy    : 0.4522\n",
      "precision   : 0.4840\n",
      "recall      : 0.8732\n",
      "specificity : 0.0000\n",
      "fpr         : 1.0000\n",
      "f1          : 0.6228\n",
      "mcc         : -0.2558\n",
      "kappa       : -0.1307\n",
      "mse         : 0.5478\n",
      "mae         : 0.5478\n",
      "auc         : 0.0607\n",
      "runtime     : 16.0145\n",
      "samples_per_second: 152.1740\n",
      "steps_per_second: 19.0450\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
