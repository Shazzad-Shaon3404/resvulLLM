{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T04:36:04.416704Z",
     "start_time": "2025-06-17T04:35:59.930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your processed dataset\n",
    "train_df = pd.read_csv(\"train_pdg_fol.csv\")\n",
    "test_df = pd.read_csv(\"test_pdg_fol.csv\")"
   ],
   "id": "a1b92f6b563a9d57",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T04:54:18.415887Z",
     "start_time": "2025-06-17T04:36:05.775869Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== STEP 1: Data Preprocessing ======\n",
    "# Rename to standardized column names\n",
    "train_df = train_df.rename(columns={\n",
    "    \"func_cleaned\": \"function\",\n",
    "    \"target\": \"label\",\n",
    "    \"fol_logic\": \"fol\"\n",
    "})\n",
    "test_df = test_df.rename(columns={\n",
    "    \"func_cleaned\": \"function\",\n",
    "    \"target\": \"label\"\n",
    "})\n",
    "\n",
    "# Drop rows with missing values\n",
    "train_df = train_df.dropna(subset=[\"fol\", \"function\", \"label\"])\n",
    "test_df = test_df.dropna(subset=[\"function\", \"label\"])\n",
    "\n",
    "\n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)\n",
    "test_df[\"label\"] = test_df[\"label\"].astype(int)\n",
    "\n",
    "# Convert to HuggingFace Datasets\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds  = Dataset.from_pandas(test_df)\n",
    "\n",
    "# ====== STEP 2: Tokenizer Setup ======\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Train: use FOL + FUNC\n",
    "def tokenize_fn_train(batch):\n",
    "    return tokenizer(\n",
    "        [\"FOL: \" + f + \" FUNC: \" + c for f, c in zip(batch[\"fol\"], batch[\"function\"])],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "# Test: use FUNC only\n",
    "def tokenize_fn_test(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"function\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "# Apply tokenizer\n",
    "train_tok = train_ds.map(tokenize_fn_train, batched=True)\n",
    "test_tok  = test_ds.map(tokenize_fn_test, batched=True)\n",
    "\n",
    "# ====== STEP 3: Prepare datasets ======\n",
    "train_tok = train_tok.rename_column('label', 'labels')\n",
    "test_tok  = test_tok.rename_column('label', 'labels')\n",
    "train_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# ====== STEP 4: Load Model ======\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "model.config.id2label = {0: \"safe\", 1: \"vuln\"}\n",
    "model.config.label2id = {\"safe\": 0, \"vuln\": 1}\n",
    "\n",
    "# ====== STEP 5: Metrics ======\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "# ====== STEP 6: Training Setup ======\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "args = TrainingArguments(\n",
    "    output_dir='./codebert_trainFOL_testFUNC',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "# ====== STEP 7: Train ======\n",
    "start_train = time.time()\n",
    "trainer.train()\n",
    "end_train = time.time()\n",
    "train_runtime = end_train - start_train\n",
    "print(f\"\\n=== Training completed in {train_runtime:.2f} seconds ({train_runtime / 60:.2f} minutes) ===\")\n",
    "\n",
    "# ====== STEP 8: Evaluate ======\n",
    "start_eval = time.time()\n",
    "metrics = trainer.evaluate()\n",
    "end_eval = time.time()\n",
    "eval_runtime = end_eval - start_eval\n",
    "print(f\"\\n=== Evaluation completed in {eval_runtime:.2f} seconds ({eval_runtime / 60:.2f} minutes) ===\")\n",
    "\n",
    "print(\"\\n=== Hold‚Äêout Metrics (Trained with FOL + FUNC, Tested with FUNC only) ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n",
    "\n",
    "# Include runtime in printed metrics\n",
    "print(f\"Train Time (s): {train_runtime:.2f}\")\n",
    "print(f\"Eval Time (s):  {eval_runtime:.2f}\")\n",
    "\n",
    "# ====== STEP 9: Save Model ======\n",
    "save_dir = './codebert_trainFOL_testFUNC_saved'\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"\\nModel and tokenizer saved to {save_dir}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shaon/.virtualenvs/PythonProject2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9821/9821 [00:19<00:00, 492.87 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4210/4210 [00:00<00:00, 5001.84 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shaon/.virtualenvs/PythonProject2/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_190319/2025832917.py:120: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4912' max='6140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4912/6140 17:16 < 04:19, 4.74 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Fpr</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.678555</td>\n",
       "      <td>0.572447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427553</td>\n",
       "      <td>0.427553</td>\n",
       "      <td>0.582837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.685900</td>\n",
       "      <td>0.670980</td>\n",
       "      <td>0.582185</td>\n",
       "      <td>0.635762</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.977178</td>\n",
       "      <td>0.022822</td>\n",
       "      <td>0.098411</td>\n",
       "      <td>0.081173</td>\n",
       "      <td>0.034513</td>\n",
       "      <td>0.417815</td>\n",
       "      <td>0.417815</td>\n",
       "      <td>0.611135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.588100</td>\n",
       "      <td>0.668013</td>\n",
       "      <td>0.607126</td>\n",
       "      <td>0.558214</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.770124</td>\n",
       "      <td>0.229876</td>\n",
       "      <td>0.458415</td>\n",
       "      <td>0.172019</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>0.392874</td>\n",
       "      <td>0.392874</td>\n",
       "      <td>0.645178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>0.710772</td>\n",
       "      <td>0.609264</td>\n",
       "      <td>0.572227</td>\n",
       "      <td>0.341111</td>\n",
       "      <td>0.809544</td>\n",
       "      <td>0.190456</td>\n",
       "      <td>0.427428</td>\n",
       "      <td>0.171029</td>\n",
       "      <td>0.158770</td>\n",
       "      <td>0.390736</td>\n",
       "      <td>0.390736</td>\n",
       "      <td>0.651767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training completed in 1036.71 seconds (17.28 minutes) ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='527' max='527' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [527/527 00:25]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation completed in 26.14 seconds (0.44 minutes) ===\n",
      "\n",
      "=== Hold‚Äêout Metrics (Trained with FOL + FUNC, Tested with FUNC only) ===\n",
      "loss        : 0.6680\n",
      "accuracy    : 0.6071\n",
      "precision   : 0.5582\n",
      "recall      : 0.3889\n",
      "specificity : 0.7701\n",
      "fpr         : 0.2299\n",
      "f1          : 0.4584\n",
      "mcc         : 0.1720\n",
      "kappa       : 0.1654\n",
      "mse         : 0.3929\n",
      "mae         : 0.3929\n",
      "auc         : 0.6452\n",
      "runtime     : 26.1339\n",
      "samples_per_second: 161.0930\n",
      "steps_per_second: 20.1650\n",
      "Train Time (s): 1036.71\n",
      "Eval Time (s):  26.14\n",
      "\n",
      "Model and tokenizer saved to ./codebert_trainFOL_testFUNC_saved\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:36:38.689150Z",
     "start_time": "2025-06-17T05:17:20.132342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== STEP 1: Data Preprocessing ======\n",
    "# Rename to standardized column names\n",
    "train_df = train_df.rename(columns={\n",
    "    \"func_cleaned\": \"function\",\n",
    "    \"target\": \"label\",\n",
    "    \"fol_logic\": \"fol\"\n",
    "})\n",
    "test_df = test_df.rename(columns={\n",
    "    \"func_cleaned\": \"function\",\n",
    "    \"target\": \"label\"\n",
    "})\n",
    "\n",
    "# Drop rows with missing values\n",
    "train_df = train_df.dropna(subset=[\"fol\", \"function\", \"label\"])\n",
    "test_df = test_df.dropna(subset=[\"function\", \"label\"])\n",
    "\n",
    "\n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)\n",
    "test_df[\"label\"] = test_df[\"label\"].astype(int)\n",
    "\n",
    "# Convert to HuggingFace Datasets\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds  = Dataset.from_pandas(test_df)\n",
    "\n",
    "# ====== STEP 2: Tokenizer Setup ======\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Train: use FOL + FUNC\n",
    "def tokenize_fn_train(batch):\n",
    "    return tokenizer(\n",
    "        [\"FOL: \" + f + \" FUNC: \" + c for f, c in zip(batch[\"fol\"], batch[\"function\"])],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "# Test: use FUNC only\n",
    "def tokenize_fn_test(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"function\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "# Apply tokenizer\n",
    "train_tok = train_ds.map(tokenize_fn_train, batched=True)\n",
    "test_tok  = test_ds.map(tokenize_fn_test, batched=True)\n",
    "\n",
    "# ====== STEP 3: Prepare datasets ======\n",
    "train_tok = train_tok.rename_column('label', 'labels')\n",
    "test_tok  = test_tok.rename_column('label', 'labels')\n",
    "train_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# ====== STEP 4: Load Model ======\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "model.config.id2label = {0: \"safe\", 1: \"vuln\"}\n",
    "model.config.label2id = {\"safe\": 0, \"vuln\": 1}\n",
    "\n",
    "# ====== STEP 5: Metrics ======\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "# ====== STEP 6: Training Setup ======\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "args = TrainingArguments(\n",
    "    output_dir='./codebert_trainFOL_testFUNC',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "# ====== STEP 7: Train ======\n",
    "start_train = time.time()\n",
    "trainer.train()\n",
    "end_train = time.time()\n",
    "train_runtime = end_train - start_train\n",
    "print(f\"\\n=== Training completed in {train_runtime:.2f} seconds ({train_runtime / 60:.2f} minutes) ===\")\n",
    "\n",
    "# ====== STEP 8: Evaluate ======\n",
    "start_eval = time.time()\n",
    "metrics = trainer.evaluate()\n",
    "end_eval = time.time()\n",
    "eval_runtime = end_eval - start_eval\n",
    "print(f\"\\n=== Evaluation completed in {eval_runtime:.2f} seconds ({eval_runtime / 60:.2f} minutes) ===\")\n",
    "\n",
    "print(\"\\n=== Hold‚Äêout Metrics (Trained with FOL + FUNC, Tested with FUNC only) ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n",
    "\n",
    "# Include runtime in printed metrics\n",
    "print(f\"Train Time (s): {train_runtime:.2f}\")\n",
    "print(f\"Eval Time (s):  {eval_runtime:.2f}\")\n",
    "\n",
    "# ====== STEP 9: Save Model ======\n",
    "save_dir = './codebertV2_trainFOL_testFUNC_saved'\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"\\nModel and tokenizer saved to {save_dir}\")"
   ],
   "id": "8cb372ee32d30105",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9821/9821 [00:20<00:00, 470.03 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4210/4210 [00:00<00:00, 4657.88 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/shaon/.virtualenvs/PythonProject2/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_190319/32077364.py:120: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4912' max='6140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4912/6140 18:24 < 04:36, 4.45 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Fpr</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.692200</td>\n",
       "      <td>0.678203</td>\n",
       "      <td>0.572447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427553</td>\n",
       "      <td>0.427553</td>\n",
       "      <td>0.582214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>0.670778</td>\n",
       "      <td>0.588124</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.104444</td>\n",
       "      <td>0.949378</td>\n",
       "      <td>0.050622</td>\n",
       "      <td>0.178199</td>\n",
       "      <td>0.101951</td>\n",
       "      <td>0.060120</td>\n",
       "      <td>0.411876</td>\n",
       "      <td>0.411876</td>\n",
       "      <td>0.626272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.737125</td>\n",
       "      <td>0.622090</td>\n",
       "      <td>0.589393</td>\n",
       "      <td>0.382778</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.199170</td>\n",
       "      <td>0.464129</td>\n",
       "      <td>0.202824</td>\n",
       "      <td>0.192132</td>\n",
       "      <td>0.377910</td>\n",
       "      <td>0.377910</td>\n",
       "      <td>0.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.520500</td>\n",
       "      <td>0.797899</td>\n",
       "      <td>0.612114</td>\n",
       "      <td>0.575840</td>\n",
       "      <td>0.352222</td>\n",
       "      <td>0.806224</td>\n",
       "      <td>0.193776</td>\n",
       "      <td>0.437091</td>\n",
       "      <td>0.178370</td>\n",
       "      <td>0.166636</td>\n",
       "      <td>0.387886</td>\n",
       "      <td>0.387886</td>\n",
       "      <td>0.649803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training completed in 1104.42 seconds (18.41 minutes) ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='527' max='527' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [527/527 00:26]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation completed in 27.10 seconds (0.45 minutes) ===\n",
      "\n",
      "=== Hold‚Äêout Metrics (Trained with FOL + FUNC, Tested with FUNC only) ===\n",
      "loss        : 0.7371\n",
      "accuracy    : 0.6221\n",
      "precision   : 0.5894\n",
      "recall      : 0.3828\n",
      "specificity : 0.8008\n",
      "fpr         : 0.1992\n",
      "f1          : 0.4641\n",
      "mcc         : 0.2028\n",
      "kappa       : 0.1921\n",
      "mse         : 0.3779\n",
      "mae         : 0.3779\n",
      "auc         : 0.6573\n",
      "runtime     : 27.0958\n",
      "samples_per_second: 155.3750\n",
      "steps_per_second: 19.4500\n",
      "Train Time (s): 1104.42\n",
      "Eval Time (s):  27.10\n",
      "\n",
      "Model and tokenizer saved to ./codebertV2_trainFOL_testFUNC_saved\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "big",
   "id": "2e2daa848519d424"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import pandas as pd\n",
    "gbig_test_df = pd.read_csv(\"big_vultest.csv\")\n",
    "gbig_test_df.info()"
   ],
   "id": "c5cbbbcf94429723"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:39:08.140826Z",
     "start_time": "2025-06-17T05:39:08.118916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "gbig_test_df = pd.read_csv(\"big_vultest.csv\")\n",
    "gbig_test_df.info()"
   ],
   "id": "1e08a2b91b0e2f89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1170 entries, 0 to 1169\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  1170 non-null   object\n",
      " 1   input        1170 non-null   object\n",
      " 2   output       1170 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 27.5+ KB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:39:50.612591Z",
     "start_time": "2025-06-17T05:39:17.656831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== LOAD SAVED MODEL ======\n",
    "saved_dir = './codebertV2_trainFOL_testFUNC_saved'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(saved_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_dir)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== LOAD AND PROCESS NEW TEST DATA ======\n",
    "# Replace with your actual new test DataFrame\n",
    "\n",
    "\n",
    "# Standardize column names and drop missing values\n",
    "gbig_test_df = gbig_test_df.rename(columns={\"input\": \"func\", \"output\": \"label\"})\n",
    "gbig_test_df = gbig_test_df.dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "gbig_test_ds = Dataset.from_pandas(gbig_test_df)\n",
    "\n",
    "# Tokenization (FUNC only, no FOL)\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"func\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "big_test_tok = gbig_test_ds.map(tokenize_fn, batched=True)\n",
    "big_test_tok = big_test_tok.rename_column(\"label\", \"labels\")\n",
    "big_test_tok.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=big_test_tok)\n",
    "\n",
    "# ====== PRINT METRICS ======\n",
    "print(\"\\n=== Evaluation on BigVul Dataset ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n"
   ],
   "id": "36106c9592fddf35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1170/1170 [00:00<00:00, 6744.30 examples/s]\n",
      "/tmp/ipykernel_190319/3843391265.py:72: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:08]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on BigVul Dataset ===\n",
      "loss        : 0.9218\n",
      "model_preparation_time: 0.0022\n",
      "accuracy    : 0.5026\n",
      "precision   : 0.5062\n",
      "recall      : 0.2085\n",
      "specificity : 0.7966\n",
      "fpr         : 0.2034\n",
      "f1          : 0.2954\n",
      "mcc         : 0.0063\n",
      "kappa       : 0.0051\n",
      "mse         : 0.4974\n",
      "mae         : 0.4974\n",
      "auc         : 0.5177\n",
      "runtime     : 9.1659\n",
      "samples_per_second: 127.6470\n",
      "steps_per_second: 16.0380\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Diverse",
   "id": "c3c9785cff7e2a6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:40:04.531790Z",
     "start_time": "2025-06-17T05:40:04.505112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "gdiv_test_df = pd.read_csv(\"diverse_test.csv\")\n",
    "gdiv_test_df.info()"
   ],
   "id": "d18b36e1eaa78b27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1532 entries, 0 to 1531\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   code_snip  1532 non-null   object\n",
      " 1   output     1532 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.1+ KB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:40:33.748503Z",
     "start_time": "2025-06-17T05:40:06.614141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== LOAD SAVED MODEL ======\n",
    "saved_dir = './codebertV2_trainFOL_testFUNC_saved'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(saved_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_dir)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== LOAD AND PROCESS NEW TEST DATA ======\n",
    "# Replace with your actual new test DataFrame\n",
    "\n",
    "\n",
    "# Standardize column names and drop missing values\n",
    "gdiv_test_df = gdiv_test_df.rename(columns={\"code_snip\": \"func\", \"output\": \"label\"})\n",
    "gdiv_test_df= gdiv_test_df.dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "gdiv_test_ds = Dataset.from_pandas(gdiv_test_df)\n",
    "\n",
    "# Tokenization (FUNC only, no FOL)\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"func\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "div_test_tok = gdiv_test_ds.map(tokenize_fn, batched=True)\n",
    "div_test_tok = div_test_tok.rename_column(\"label\", \"labels\")\n",
    "div_test_tok.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=div_test_tok)\n",
    "\n",
    "# ====== PRINT METRICS ======\n",
    "print(\"\\n=== Evaluation on Diverse Dataset ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n"
   ],
   "id": "5cadaaa08b5bd9d8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1532/1532 [00:00<00:00, 8687.40 examples/s]\n",
      "/tmp/ipykernel_190319/1272051200.py:72: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:09]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Diverse Dataset ===\n",
      "loss        : 0.9425\n",
      "model_preparation_time: 0.0018\n",
      "accuracy    : 0.5085\n",
      "precision   : 0.5215\n",
      "recall      : 0.2063\n",
      "specificity : 0.8107\n",
      "fpr         : 0.1893\n",
      "f1          : 0.2956\n",
      "mcc         : 0.0213\n",
      "kappa       : 0.0170\n",
      "mse         : 0.4915\n",
      "mae         : 0.4915\n",
      "auc         : 0.5301\n",
      "runtime     : 9.8103\n",
      "samples_per_second: 156.1630\n",
      "steps_per_second: 19.5710\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "juliet",
   "id": "36585daa85373e1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:41:31.533133Z",
     "start_time": "2025-06-17T05:41:31.504480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "juliet_test_df = pd.read_csv(\"djuliet_test.csv\")\n",
    "juliet_test_df.info()"
   ],
   "id": "137c76736b12cc95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3152 entries, 0 to 3151\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   code_snip  3152 non-null   object\n",
      " 1   output     3152 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 49.4+ KB\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:42:11.822209Z",
     "start_time": "2025-06-17T05:41:34.313138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== LOAD SAVED MODEL ======\n",
    "saved_dir = './codebertV2_trainFOL_testFUNC_saved'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(saved_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_dir)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== LOAD AND PROCESS NEW TEST DATA ======\n",
    "# Replace with your actual new test DataFrame\n",
    "\n",
    "\n",
    "# Standardize column names and drop missing values\n",
    "juliet_test_df = juliet_test_df.rename(columns={\"code_snip\": \"func\", \"output\": \"label\"})\n",
    "juliet_test_df = juliet_test_df.dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "juliet_test_ds = Dataset.from_pandas(juliet_test_df)\n",
    "\n",
    "# Tokenization (FUNC only, no FOL)\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"func\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "juliet_test_tok = juliet_test_ds.map(tokenize_fn, batched=True)\n",
    "juliet_test_tok = juliet_test_tok.rename_column(\"label\", \"labels\")\n",
    "juliet_test_tok.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=juliet_test_tok)\n",
    "\n",
    "# ====== PRINT METRICS ======\n",
    "print(\"\\n=== Evaluation on Juliet Dataset ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n"
   ],
   "id": "2483441e98bc84ff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3152/3152 [00:00<00:00, 10020.94 examples/s]\n",
      "/tmp/ipykernel_190319/744574558.py:72: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='394' max='394' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [394/394 00:19]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Juliet Dataset ===\n",
      "loss        : 1.0975\n",
      "model_preparation_time: 0.0019\n",
      "accuracy    : 0.5124\n",
      "precision   : 0.6466\n",
      "recall      : 0.0546\n",
      "specificity : 0.9702\n",
      "fpr         : 0.0298\n",
      "f1          : 0.1006\n",
      "mcc         : 0.0615\n",
      "kappa       : 0.0247\n",
      "mse         : 0.4876\n",
      "mae         : 0.4876\n",
      "auc         : 0.5801\n",
      "runtime     : 19.7887\n",
      "samples_per_second: 159.2830\n",
      "steps_per_second: 19.9100\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "reveal",
   "id": "b81abb585f333f72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:45:03.038621Z",
     "start_time": "2025-06-17T05:45:03.010273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "reveal_test_df = pd.read_csv(\"Reveal_vultest.csv\")\n",
    "reveal_test_df.info()"
   ],
   "id": "8e19ffcbfd3b154e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2028 entries, 0 to 2027\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  2028 non-null   object\n",
      " 1   input        2028 non-null   object\n",
      " 2   output       2028 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 47.7+ KB\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:45:35.057181Z",
     "start_time": "2025-06-17T05:45:05.654994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== LOAD SAVED MODEL ======\n",
    "saved_dir ='./codebertV2_trainFOL_testFUNC_saved'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(saved_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_dir)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== LOAD AND PROCESS NEW TEST DATA ======\n",
    "# Replace with your actual new test DataFrame\n",
    "reveal_test_df = pd.read_csv(\"Reveal_vultest.csv\")\n",
    "\n",
    "# Standardize column names and drop missing values\n",
    "reveal_test_df = reveal_test_df.rename(columns={\"input\": \"func\", \"output\": \"label\"})\n",
    "reveal_test_df = reveal_test_df.dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "reveal_test_ds = Dataset.from_pandas(reveal_test_df)\n",
    "\n",
    "# Tokenization (FUNC only, no FOL)\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"func\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "reveal_test_tok = reveal_test_ds.map(tokenize_fn, batched=True)\n",
    "reveal_test_tok = reveal_test_tok.rename_column(\"label\", \"labels\")\n",
    "reveal_test_tok.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=reveal_test_tok)\n",
    "\n",
    "# ====== PRINT METRICS ======\n",
    "print(\"\\n=== Evaluation on Reveal Dataset ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n"
   ],
   "id": "8f811f8ed2753326",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2028/2028 [00:00<00:00, 9358.00 examples/s]\n",
      "/tmp/ipykernel_190319/2482279945.py:72: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='254' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [254/254 00:12]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Reveal Dataset ===\n",
      "loss        : 0.9853\n",
      "model_preparation_time: 0.0018\n",
      "accuracy    : 0.5133\n",
      "precision   : 0.5611\n",
      "recall      : 0.1223\n",
      "specificity : 0.9043\n",
      "fpr         : 0.0957\n",
      "f1          : 0.2008\n",
      "mcc         : 0.0427\n",
      "kappa       : 0.0266\n",
      "mse         : 0.4867\n",
      "mae         : 0.4867\n",
      "auc         : 0.5741\n",
      "runtime     : 12.8956\n",
      "samples_per_second: 157.2620\n",
      "steps_per_second: 19.6970\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "mixvul",
   "id": "780094a1e574bde7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:45:46.319235Z",
     "start_time": "2025-06-17T05:45:46.289303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "mix_test_df = pd.read_csv(\"mix_test_vultest.csv\")\n",
    "mix_test_df.info()"
   ],
   "id": "8ee6f81dd153dd6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2864 entries, 0 to 2863\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  2864 non-null   object\n",
      " 1   input        2864 non-null   object\n",
      " 2   output       2864 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 67.2+ KB\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:46:22.714027Z",
     "start_time": "2025-06-17T05:45:48.080775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== LOAD SAVED MODEL ======\n",
    "saved_dir = './codebertV2_trainFOL_testFUNC_saved'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(saved_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_dir)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== LOAD AND PROCESS NEW TEST DATA ======\n",
    "\n",
    "\n",
    "# Standardize column names and drop missing values\n",
    "mix_test_df = mix_test_df.rename(columns={\"input\": \"func\", \"output\": \"label\"})\n",
    "mix_test_df = mix_test_df.dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "mix_test_ds = Dataset.from_pandas(mix_test_df)\n",
    "\n",
    "# Tokenization (FUNC only, no FOL)\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"func\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "mix_test_tok = mix_test_ds.map(tokenize_fn, batched=True)\n",
    "mix_test_tok = mix_test_tok.rename_column(\"label\", \"labels\")\n",
    "mix_test_tok.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=mix_test_tok)\n",
    "\n",
    "# ====== PRINT METRICS ======\n",
    "print(\"\\n=== Evaluation on mix Dataset ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n"
   ],
   "id": "c037d6e14ed4c1b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2864/2864 [00:00<00:00, 9793.22 examples/s]\n",
      "/tmp/ipykernel_190319/4160617190.py:71: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='358' max='358' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [358/358 00:17]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on mix Dataset ===\n",
      "loss        : 0.8757\n",
      "model_preparation_time: 0.0018\n",
      "accuracy    : 0.5482\n",
      "precision   : 0.6052\n",
      "recall      : 0.2772\n",
      "specificity : 0.8191\n",
      "fpr         : 0.1809\n",
      "f1          : 0.3803\n",
      "mcc         : 0.1147\n",
      "kappa       : 0.0964\n",
      "mse         : 0.4518\n",
      "mae         : 0.4518\n",
      "auc         : 0.5931\n",
      "runtime     : 17.6332\n",
      "samples_per_second: 162.4210\n",
      "steps_per_second: 20.3030\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "cvefix",
   "id": "d60703f769117a2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:47:07.353973Z",
     "start_time": "2025-06-17T05:47:07.312664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "fun_test_df = pd.read_json(\"test_512.json\")\n",
    "fun_test_df.info()"
   ],
   "id": "39673b6620fb72a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4216 entries, 0 to 4215\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  4216 non-null   object\n",
      " 1   input        4216 non-null   object\n",
      " 2   output       4216 non-null   int64 \n",
      " 3   idx          4216 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 131.9+ KB\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T05:47:54.673624Z",
     "start_time": "2025-06-17T05:47:09.271034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "# ====== LOAD SAVED MODEL ======\n",
    "saved_dir = './codebertV2_trainFOL_testFUNC_saved'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(saved_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_dir)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# ====== LOAD AND PROCESS NEW TEST DATA ======\n",
    "# Replace with your actual new test DataFrame\n",
    "\n",
    "\n",
    "# Standardize column names and drop missing values\n",
    "fun_test_df = fun_test_df.rename(columns={\"input\": \"func\", \"output\": \"label\"})\n",
    "fun_test_df = fun_test_df.dropna(subset=[\"func\", \"label\"])\n",
    "\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "fun_test_ds = Dataset.from_pandas(fun_test_df)\n",
    "\n",
    "# Tokenization (FUNC only, no FOL)\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        [\"FUNC: \" + c for c in batch[\"func\"]],\n",
    "        truncation=True, padding='max_length', max_length=256\n",
    "    )\n",
    "\n",
    "fun_test_tok = fun_test_ds.map(tokenize_fn, batched=True)\n",
    "fun_test_tok = fun_test_tok.rename_column(\"label\", \"labels\")\n",
    "fun_test_tok.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=fun_test_tok)\n",
    "\n",
    "# ====== PRINT METRICS ======\n",
    "print(\"\\n=== Evaluation on VULLM fol without Dataset ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n"
   ],
   "id": "85f1becf5d66a15c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4216/4216 [00:00<00:00, 9785.76 examples/s] \n",
      "/tmp/ipykernel_190319/2345004140.py:72: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='527' max='527' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [527/527 00:26]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on VULLM fol without Dataset ===\n",
      "loss        : 0.9417\n",
      "model_preparation_time: 0.0018\n",
      "accuracy    : 0.5007\n",
      "precision   : 0.5015\n",
      "recall      : 0.2410\n",
      "specificity : 0.7604\n",
      "fpr         : 0.2396\n",
      "f1          : 0.3255\n",
      "mcc         : 0.0017\n",
      "kappa       : 0.0014\n",
      "mse         : 0.4993\n",
      "mae         : 0.4993\n",
      "auc         : 0.4974\n",
      "runtime     : 26.5880\n",
      "samples_per_second: 158.5680\n",
      "steps_per_second: 19.8210\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
