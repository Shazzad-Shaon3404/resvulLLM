{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df  = pd.read_csv('test_data.csv')"
   ],
   "id": "ff8b7d66c2b44876",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "CODET5 without FOL",
   "id": "49ed2d6679be999f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    matthews_corrcoef, cohen_kappa_score,\n",
    "    mean_squared_error, mean_absolute_error,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df[\"label\"] = le.fit_transform(train_df[\"target\"])\n",
    "test_df[\"label\"]  = le.transform(test_df[\"target\"])\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[[\"func_cleaned\",\"label\"]])\n",
    "test_ds  = Dataset.from_pandas(test_df[[\"func_cleaned\",\"label\"]])\n",
    "\n",
    "\n",
    "model_name = \"Salesforce/codet5-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"func_cleaned\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(preprocess, batched=True)\n",
    "test_ds  = test_ds.map(preprocess,  batched=True)\n",
    "\n",
    "train_ds.set_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
    "test_ds.set_format( \"torch\", columns=[\"input_ids\",\"attention_mask\",\"label\"])\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds   = np.argmax(p.predictions, axis=1)\n",
    "    labels  = p.label_ids\n",
    "    probs   = p.predictions  # logits\n",
    "\n",
    "    acc      = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    mcc      = matthews_corrcoef(labels, preds)\n",
    "    kappa    = cohen_kappa_score(labels, preds)\n",
    "    mse      = mean_squared_error(labels, preds)\n",
    "    mae      = mean_absolute_error(labels, preds)\n",
    "\n",
    "    cm   = confusion_matrix(labels, preds)\n",
    "    tp   = np.diag(cm)\n",
    "    fn   = cm.sum(axis=1) - tp\n",
    "    fp   = cm.sum(axis=0) - tp\n",
    "    tn   = cm.sum() - (tp + fn + fp)\n",
    "    spec = np.mean(tn / (tn + fp + 1e-12))\n",
    "    sens = np.mean(tp / (tp + fn + 1e-12))\n",
    "    fpr  = np.mean(fp / (fp + tn + 1e-12))\n",
    "\n",
    "    lb    = label_binarize(labels, classes=list(range(num_labels)))\n",
    "    try:\n",
    "        auc = roc_auc_score(lb, probs, average=\"macro\", multi_class=\"ovr\")\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\":    acc,\n",
    "        \"Precision\":   prec,\n",
    "        \"Recall\":      rec,\n",
    "        \"F1\":          f1,\n",
    "        \"MCC\":         mcc,\n",
    "        \"Kappa\":       kappa,\n",
    "        \"MSE\":         mse,\n",
    "        \"MAE\":         mae,\n",
    "        \"Specificity\": spec,\n",
    "        \"Sensitivity\": sens,\n",
    "        \"FPR\":         fpr,\n",
    "        \"AUC\":         auc,\n",
    "    }\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir               = \"./codet5-results\",\n",
    "    eval_strategy            = \"epoch\",\n",
    "    save_strategy            = \"epoch\",\n",
    "    num_train_epochs         = 5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size  = 8,\n",
    "    learning_rate            = 2e-5,\n",
    "    load_best_model_at_end   = True,\n",
    "    metric_for_best_model    = \"Accuracy\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_ds,\n",
    "    eval_dataset    = test_ds,\n",
    "    tokenizer       = tokenizer,\n",
    "    compute_metrics = compute_metrics,\n",
    "    callbacks       = [EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With_fol",
   "id": "ad8f64a4ebbd2e63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "train_df = pd.read_csv('train_fol.csv')\n",
    "test_df  = pd.read_csv('test_fol.csv')\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['target'] = df['target'].astype(int)\n",
    "    df['model_input'] = df['fol_logic'].fillna('') + \" // LOGIC: \" + df['func_cleaned']\n",
    "\n",
    "# HuggingFace Datasets\n",
    "train_ds = Dataset.from_pandas(train_df[['model_input', 'target']].rename(columns={'model_input': 'text', 'target': 'label'}))\n",
    "test_ds  = Dataset.from_pandas(test_df[['model_input', 'target']].rename(columns={'model_input': 'text', 'target': 'label'}))\n"
   ],
   "id": "d434946abb18df01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True)\n",
    "test_tok  = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_tok = train_tok.rename_column('label', 'labels')\n",
    "test_tok  = test_tok.rename_column('label', 'labels')\n",
    "train_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'Salesforce/codet5-base',\n",
    "    num_labels=2\n",
    ")\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "model.config.id2label = {0: \"safe\", 1: \"vuln\"}\n",
    "model.config.label2id = {\"safe\": 0, \"vuln\": 1}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:,1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn/(tn+fp) if (tn+fp)>0 else 0,\n",
    "        \"fpr\":         fp/(fp+tn) if (fp+tn)>0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "args = TrainingArguments(\n",
    "    output_dir='./codet5_fol',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(\"\\n=== Hold‐out Metrics ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n",
    "\n",
    "\n",
    "save_dir = './codet5_fol_saved'\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"\\nModel and tokenizer saved to {save_dir}\")\n"
   ],
   "id": "b86496d9c166257c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SAnta coder with fol",
   "id": "671bc299b7f93506"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('train_df.csv')\n",
    "test_df  = pd.read_csv('test_df.csv')\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['target'] = df['target'].astype(int)\n",
    "    df['model_input'] = df['fol_logic'].fillna('') + \" // LOGIC: \" + df['func_cleaned']\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[['model_input', 'target']].rename(columns={'model_input': 'text', 'target': 'label'}))\n",
    "test_ds  = Dataset.from_pandas(test_df[['model_input', 'target']].rename(columns={'model_input': 'text', 'target': 'label'}))\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bigcode/santacoder')\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=256)\n",
    "\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True)\n",
    "test_tok  = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_tok = train_tok.rename_column('label', 'labels')\n",
    "test_tok  = test_tok.rename_column('label', 'labels')\n",
    "train_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tok.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bigcode/santacoder',\n",
    "    num_labels=2,\n",
    "    trust_remote_code=True  # important for decoder-only models\n",
    ")\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "model.config.id2label = {0: \"safe\", 1: \"vuln\"}\n",
    "model.config.label2id = {\"safe\": 0, \"vuln\": 1}\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:,1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn/(tn+fp) if (tn+fp)>0 else 0,\n",
    "        \"fpr\":         fp/(fp+tn) if (fp+tn)>0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "args = TrainingArguments(\n",
    "    output_dir='./santacoder_fol',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_steps=50,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=test_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(\"\\n=== Hold‐out Metrics ===\")\n",
    "for key, value in metrics.items():\n",
    "    if key.startswith(\"eval_\"):\n",
    "        print(f\"{key[5:]:<12}: {value:.4f}\")\n",
    "\n",
    "save_dir = './santacoder_fol_saved'\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"\\nModel and tokenizer saved to {save_dir}\")\n"
   ],
   "id": "ac12f00fd7c0d0db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "without fol",
   "id": "dc28d7901b50b9cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df  = pd.read_csv('test_data.csv')"
   ],
   "id": "f1d9c504c1c81b0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    matthews_corrcoef, cohen_kappa_score,\n",
    "    mean_squared_error, mean_absolute_error,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df[\"label\"] = le.fit_transform(train_df[\"target\"])\n",
    "test_df[\"label\"]  = le.transform(test_df[\"target\"])\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[[\"func_cleaned\", \"label\"]])\n",
    "test_ds  = Dataset.from_pandas(test_df[[\"func_cleaned\", \"label\"]])\n",
    "\n",
    "\n",
    "model_name = \"bigcode/santacoder\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"func_cleaned\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(preprocess, batched=True)\n",
    "test_ds  = test_ds.map(preprocess,  batched=True)\n",
    "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_ds.set_format( \"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds   = np.argmax(p.predictions, axis=1)\n",
    "    labels  = p.label_ids\n",
    "    probs   = p.predictions\n",
    "\n",
    "    acc      = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    mcc      = matthews_corrcoef(labels, preds)\n",
    "    kappa    = cohen_kappa_score(labels, preds)\n",
    "    mse      = mean_squared_error(labels, preds)\n",
    "    mae      = mean_absolute_error(labels, preds)\n",
    "\n",
    "    cm   = confusion_matrix(labels, preds)\n",
    "    tp   = np.diag(cm)\n",
    "    fn   = cm.sum(axis=1) - tp\n",
    "    fp   = cm.sum(axis=0) - tp\n",
    "    tn   = cm.sum() - (tp + fn + fp)\n",
    "    spec = np.mean(tn / (tn + fp + 1e-12))\n",
    "    sens = np.mean(tp / (tp + fn + 1e-12))\n",
    "    fpr  = np.mean(fp / (fp + tn + 1e-12))\n",
    "\n",
    "    lb = label_binarize(labels, classes=list(range(num_labels)))\n",
    "    try:\n",
    "        auc = roc_auc_score(lb, probs, average=\"macro\", multi_class=\"ovr\")\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\":    acc,\n",
    "        \"Precision\":   prec,\n",
    "        \"Recall\":      rec,\n",
    "        \"F1\":          f1,\n",
    "        \"MCC\":         mcc,\n",
    "        \"Kappa\":       kappa,\n",
    "        \"MSE\":         mse,\n",
    "        \"MAE\":         mae,\n",
    "        \"Specificity\": spec,\n",
    "        \"Sensitivity\": sens,\n",
    "        \"FPR\":         fpr,\n",
    "        \"AUC\":         auc,\n",
    "    }\n",
    "\n",
    "# 6. Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./santacoder-results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"Accuracy\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "results = trainer.evaluate()\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "for k, v in results.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ],
   "id": "8e3e87d9ee6f4e07",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
