{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T16:20:58.415887Z",
     "start_time": "2025-07-05T16:20:57.253997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('devign.csv')\n",
    "df.info()"
   ],
   "id": "fb25d905dfe652bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14032 entries, 0 to 14031\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   func          14032 non-null  object\n",
      " 1   func_cleaned  14032 non-null  object\n",
      " 2   project       14032 non-null  object\n",
      " 3   target        14032 non-null  bool  \n",
      "dtypes: bool(1), object(3)\n",
      "memory usage: 342.7+ KB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T15:45:08.199879Z",
     "start_time": "2025-07-05T15:45:08.189810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['target'].astype(int)\n",
    "df.info()"
   ],
   "id": "1d184c7c6d84e5a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14032 entries, 0 to 14031\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   func          14032 non-null  object\n",
      " 1   func_cleaned  14032 non-null  object\n",
      " 2   project       14032 non-null  object\n",
      " 3   target        14032 non-null  bool  \n",
      "dtypes: bool(1), object(3)\n",
      "memory usage: 342.7+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T16:21:13.397462Z",
     "start_time": "2025-07-05T16:21:13.392903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "def semgrep_trace(code, rule_path=\"p/cwe-top-25\"):\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".c\", mode=\"w\") as tmp:\n",
    "        tmp.write(code)\n",
    "        tmp_filename = tmp.name\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"semgrep\", \"--config\", rule_path, tmp_filename, \"--json\"],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            timeout=10,\n",
    "        )\n",
    "        findings = json.loads(result.stdout).get(\"results\", [])\n",
    "        if not findings:\n",
    "            return \"No_issue_found\"\n",
    "        traces = []\n",
    "        for f in findings:\n",
    "            rule = f.get(\"check_id\", \"unknown_rule\")\n",
    "            start = f.get(\"start\", {}).get(\"line\", \"NA\")\n",
    "            traces.append(f\"{rule}@L{start}\")\n",
    "        return \"; \".join(traces)\n",
    "    except Exception as e:\n",
    "        return \"Error_or_Timeout\"\n",
    "    finally:\n",
    "        os.remove(tmp_filename)\n"
   ],
   "id": "647b684f5ba65f9e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T04:17:11.799930Z",
     "start_time": "2025-07-05T16:21:16.131994Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"event_trace\"] = df[\"func\"].apply(semgrep_trace)\n",
   "id": "8328c431303532bc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T10:28:05.619094Z",
     "start_time": "2025-07-06T10:28:04.585956Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"event_trace.csv\",index=False,quoting=1)",
   "id": "14aa301772050bb8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T15:05:29.495312Z",
     "start_time": "2025-07-06T15:05:29.490139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DANGEROUS_CALLS = {\n",
    "    # Buffer overflows, format strings, etc.\n",
    "    \"strcpy\": \"buffer_overflow\",\n",
    "    \"strcat\": \"buffer_overflow\",\n",
    "    \"sprintf\": \"format_string\",\n",
    "    \"vsprintf\": \"format_string\",\n",
    "    \"gets\": \"buffer_overflow\",\n",
    "    \"scanf\": \"input_unsanitized\",\n",
    "    \"sscanf\": \"input_unsanitized\",\n",
    "    \"fscanf\": \"input_unsanitized\",\n",
    "    \"memcpy\": \"buffer_overflow\",\n",
    "    \"strncpy\": \"buffer_overflow\",\n",
    "    \"strncat\": \"buffer_overflow\",\n",
    "    \"memset\": \"buffer_operation\",\n",
    "    \"memmove\": \"buffer_overflow\",\n",
    "    \"strlen\": \"buffer_operation\",\n",
    "    \"read\": \"buffer_overflow\",\n",
    "    \"write\": \"buffer_overflow\",\n",
    "    # Dangerous system interaction\n",
    "    \"system\": \"command_injection\",\n",
    "    \"popen\": \"command_injection\",\n",
    "    \"exec\": \"command_injection\",\n",
    "    \"execl\": \"command_injection\",\n",
    "    \"execlp\": \"command_injection\",\n",
    "    \"execle\": \"command_injection\",\n",
    "    \"execv\": \"command_injection\",\n",
    "    \"execvp\": \"command_injection\",\n",
    "    \"execve\": \"command_injection\",\n",
    "    # Memory management\n",
    "    \"malloc\": \"memory_alloc\",\n",
    "    \"calloc\": \"memory_alloc\",\n",
    "    \"realloc\": \"memory_alloc\",\n",
    "    \"free\": \"memory_free\",\n",
    "    \"delete\": \"memory_free\",\n",
    "    \"delete[]\": \"memory_free\",\n",
    "    \"new\": \"memory_alloc\",\n",
    "    # Pointer arithmetic, dangerous casts\n",
    "    \"reinterpret_cast\": \"dangerous_cast\",\n",
    "    \"const_cast\": \"dangerous_cast\",\n",
    "    # Network functions\n",
    "    \"recv\": \"network_input\",\n",
    "    \"send\": \"network_output\",\n",
    "    \"accept\": \"network_input\",\n",
    "    \"connect\": \"network_output\",\n",
    "    \"bind\": \"network_input\",\n",
    "    \"listen\": \"network_input\",\n",
    "    \"inet_addr\": \"network_input\",\n",
    "    # Misc\n",
    "    \"chown\": \"privilege_escalation\",\n",
    "    \"chmod\": \"privilege_escalation\",\n",
    "    \"fopen\": \"file_operation\",\n",
    "    \"fclose\": \"file_operation\",\n",
    "    \"fread\": \"file_operation\",\n",
    "    \"fwrite\": \"file_operation\",\n",
    "    # Add more as needed\n",
    "}\n"
   ],
   "id": "ba8085190efbfb5a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T15:05:36.379795Z",
     "start_time": "2025-07-06T15:05:36.371936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def extract_event_trace_from_ast(ast_path):\n",
    "    # Load the AST JSON file\n",
    "    with open(ast_path, \"r\") as f:\n",
    "        ast_json = json.load(f)\n",
    "    event_trace = []\n",
    "    # --- Track pointer names and free usage for UAF/double-free ---\n",
    "    freed_pointers = set()\n",
    "    pointer_names = set()\n",
    "    free_lines = {}\n",
    "    for node in ast_json.get('nodes', []):\n",
    "        label = node.get('label', '')\n",
    "        code = node.get('code', '')\n",
    "        line = node.get('lineNumber', '?')\n",
    "        # --- Dangerous API calls ---\n",
    "        if label == 'CALL':\n",
    "            for func, vuln_type in DANGEROUS_CALLS.items():\n",
    "                if func in code:\n",
    "                    event_trace.append(f\"{vuln_type}:{func}@L{line}\")\n",
    "            # Track free() calls for UAF/Double-Free\n",
    "            if 'free' in code:\n",
    "                # Try to extract pointer var name (basic heuristic)\n",
    "                tokens = code.split('free')\n",
    "                if len(tokens) > 1:\n",
    "                    ptr_name = tokens[1].replace('(', '').replace(')', '').replace(';','').strip()\n",
    "                    if ptr_name:\n",
    "                        if ptr_name in freed_pointers:\n",
    "                            event_trace.append(f\"double_free:{ptr_name}@L{line}\")\n",
    "                        freed_pointers.add(ptr_name)\n",
    "                        free_lines[ptr_name] = line\n",
    "        # --- Pointer usage (look for use-after-free) ---\n",
    "        # Very basic: look for use of pointers (dereference or member access) after free\n",
    "        if label == 'IDENTIFIER' and '*' in code:\n",
    "            pointer_names.add(code.replace('*','').strip())\n",
    "        if label in ('CALL', 'FIELD_IDENTIFIER', 'IDENTIFIER'):\n",
    "            for ptr in freed_pointers:\n",
    "                if ptr and ptr in code and 'free' not in code:\n",
    "                    event_trace.append(f\"use_after_free:{ptr}@L{line}\")\n",
    "        # --- Checks ---\n",
    "        if label == 'CONTROL_STRUCTURE':\n",
    "            cond = code.lower()\n",
    "            if 'if' in cond:\n",
    "                if any(op in cond for op in ['<', '>', '!=', '==', '>=', '<=']):\n",
    "                    event_trace.append(f\"check@L{line}\")\n",
    "                if 'null' in cond or 'nullptr' in cond or '0' in cond:\n",
    "                    event_trace.append(f\"null_check@L{line}\")\n",
    "                if 'strlen' in cond or 'sizeof' in cond:\n",
    "                    event_trace.append(f\"length_check@L{line}\")\n",
    "    if not event_trace:\n",
    "        return \"No_issue_found\"\n",
    "    # Remove duplicates while keeping order\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for ev in event_trace:\n",
    "        if ev not in seen:\n",
    "            seen.add(ev)\n",
    "            unique.append(ev)\n",
    "    return \"; \".join(unique)\n"
   ],
   "id": "edc623eb609d9e30",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T15:35:43.686754Z",
     "start_time": "2025-07-06T15:35:43.681971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DANGEROUS_CALLS = {\n",
    "    \"strcpy\": \"buffer_overflow\",\n",
    "    \"strcat\": \"buffer_overflow\",\n",
    "    \"sprintf\": \"format_string\",\n",
    "    \"vsprintf\": \"format_string\",\n",
    "    \"gets\": \"buffer_overflow\",\n",
    "    \"scanf\": \"input_unsanitized\",\n",
    "    \"sscanf\": \"input_unsanitized\",\n",
    "    \"fscanf\": \"input_unsanitized\",\n",
    "    \"memcpy\": \"buffer_overflow\",\n",
    "    \"strncpy\": \"buffer_overflow\",\n",
    "    \"strncat\": \"buffer_overflow\",\n",
    "    \"memset\": \"buffer_operation\",\n",
    "    \"memmove\": \"buffer_overflow\",\n",
    "    \"strlen\": \"buffer_operation\",\n",
    "    \"read\": \"buffer_overflow\",\n",
    "    \"write\": \"buffer_overflow\",\n",
    "    \"system\": \"command_injection\",\n",
    "    \"popen\": \"command_injection\",\n",
    "    \"exec\": \"command_injection\",\n",
    "    \"execl\": \"command_injection\",\n",
    "    \"execlp\": \"command_injection\",\n",
    "    \"execle\": \"command_injection\",\n",
    "    \"execv\": \"command_injection\",\n",
    "    \"execvp\": \"command_injection\",\n",
    "    \"execve\": \"command_injection\",\n",
    "    \"malloc\": \"memory_alloc\",\n",
    "    \"calloc\": \"memory_alloc\",\n",
    "    \"realloc\": \"memory_alloc\",\n",
    "    \"free\": \"memory_free\",\n",
    "    \"delete\": \"memory_free\",\n",
    "    \"delete[]\": \"memory_free\",\n",
    "    \"new\": \"memory_alloc\",\n",
    "    \"reinterpret_cast\": \"dangerous_cast\",\n",
    "    \"const_cast\": \"dangerous_cast\",\n",
    "    \"recv\": \"network_input\",\n",
    "    \"send\": \"network_output\",\n",
    "    \"accept\": \"network_input\",\n",
    "    \"connect\": \"network_output\",\n",
    "    \"bind\": \"network_input\",\n",
    "    \"listen\": \"network_input\",\n",
    "    \"inet_addr\": \"network_input\",\n",
    "    \"chown\": \"privilege_escalation\",\n",
    "    \"chmod\": \"privilege_escalation\",\n",
    "    \"fopen\": \"file_operation\",\n",
    "    \"fclose\": \"file_operation\",\n",
    "    \"fread\": \"file_operation\",\n",
    "    \"fwrite\": \"file_operation\",\n",
    "}\n"
   ],
   "id": "1e222ca08011cac6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T15:36:24.783424Z",
     "start_time": "2025-07-06T15:36:24.777445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_event_trace_from_edges(ast_json):\n",
    "    event_trace = []\n",
    "    calls = []\n",
    "    frees = set()\n",
    "    pointer_uses = []\n",
    "    freed_ptrs = {}\n",
    "    call_lines = {}\n",
    "    # Compile regex for call node extraction\n",
    "    call_re = re.compile(r'call\\(\\\"([^\\\"]+)\\\"\\)')\n",
    "    identifier_re = re.compile(r'identifier\\(\\\"([^\\\"]+)\\\"\\)')\n",
    "\n",
    "    # 1. Find all call nodes and process them\n",
    "    for edge in ast_json.get(\"edges\", []):\n",
    "        # Check if src or dst is a function call\n",
    "        for direction in [\"src\", \"dst\"]:\n",
    "            node = edge[direction]\n",
    "            # Extract call info\n",
    "            call_match = call_re.search(node)\n",
    "            if call_match:\n",
    "                call_content = call_match.group(1)\n",
    "                # Dangerous function call detection\n",
    "                for func, vuln in DANGEROUS_CALLS.items():\n",
    "                    # Match whole word function (avoid substrings)\n",
    "                    if re.search(r\"\\b\" + re.escape(func) + r\"\\b\", call_content):\n",
    "                        event_trace.append(f\"{vuln}:{func}\")\n",
    "                # Memory management (track frees)\n",
    "                if re.match(r\"free\\s*\\(([^)]+)\\)\", call_content):\n",
    "                    freed_var = re.match(r\"free\\s*\\(([^)]+)\\)\", call_content).group(1).strip()\n",
    "                    if freed_var in frees:\n",
    "                        event_trace.append(f\"double_free:{freed_var}\")\n",
    "                    frees.add(freed_var)\n",
    "                    freed_ptrs[freed_var] = True\n",
    "                # Detect basic pointer use (very basic)\n",
    "                ptr_use = re.findall(r\"\\*([a-zA-Z_][a-zA-Z0-9_]*)\", call_content)\n",
    "                pointer_uses.extend(ptr_use)\n",
    "                # Detect if-NULL or similar\n",
    "                if \"if\" in call_content and (\"null\" in call_content.lower() or \"nullptr\" in call_content.lower() or \"!=\" in call_content):\n",
    "                    event_trace.append(\"null_check\")\n",
    "            # Pointer identifier detection (use-after-free)\n",
    "            id_match = identifier_re.search(node)\n",
    "            if id_match:\n",
    "                var_name = id_match.group(1)\n",
    "                if var_name in freed_ptrs:\n",
    "                    event_trace.append(f\"use_after_free:{var_name}\")\n",
    "\n",
    "    # Remove duplicates, keep order\n",
    "    seen = set()\n",
    "    unique_events = []\n",
    "    for evt in event_trace:\n",
    "        if evt not in seen:\n",
    "            seen.add(evt)\n",
    "            unique_events.append(evt)\n",
    "    return \"; \".join(unique_events) if unique_events else \"No_issue_found\"\n"
   ],
   "id": "738a5320dc845b88",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T15:39:40.099897Z",
     "start_time": "2025-07-06T15:37:48.802364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"devign.csv\")\n",
    "df = df.iloc[:-1]\n",
    "\n",
    "\n",
    "def get_ast_path(idx):\n",
    "    return f\"/mnt/c/Users/user01/PycharmProjects/PythonProject2/joern_outputs/sample_{idx}/ast.json\"\n",
    "\n",
    "df[\"ast_path\"] = df.index.map(get_ast_path)\n",
    "\n",
    "df[\"event_trace\"] = df[\"ast_path\"].apply(lambda p: extract_event_trace_from_edges(json.load(open(p))))\n",
    "\n",
    "\n",
    "df.to_csv(\"devign_with_event_trace.csv\", index=False)\n"
   ],
   "id": "82bf7e10ddaf0577",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:03:35.912006Z",
     "start_time": "2025-07-06T16:03:35.904880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def extract_event_trace(graph_json):\n",
    "    nodes = {str(n['id']): n for n in graph_json['nodes']}\n",
    "    edges = graph_json['edges']\n",
    "\n",
    "    # Find METHOD node (the function itself)\n",
    "    method_nodes = [n for n in nodes.values() if n['label'].strip('\"') == 'METHOD']\n",
    "    if not method_nodes:\n",
    "        return []\n",
    "    method = method_nodes[0]\n",
    "\n",
    "    # Get AST root for the function body\n",
    "    ast_body_edges = [e for e in edges if e['src'] == method['id'] and e['label'] == '\"AST\"']\n",
    "    body_id = None\n",
    "    for e in ast_body_edges:\n",
    "        dst = nodes.get(str(e['dst']))\n",
    "        if dst and dst['label'].strip('\"') == 'BLOCK':\n",
    "            body_id = dst['id']\n",
    "            break\n",
    "    if not body_id:\n",
    "        return []\n",
    "\n",
    "    # Recursively traverse AST for this body\n",
    "    trace = []\n",
    "    def walk_ast(node_id):\n",
    "        node = nodes[str(node_id)]\n",
    "        label = node['label'].strip('\"')\n",
    "        code = node.get('CODE', '').strip('\"')\n",
    "        if label == \"LOCAL\":\n",
    "            t_full = node['TYPE_FULL_NAME'].strip('\"')\n",
    "            name = node['NAME'].strip('\"')\n",
    "            trace.append(f\"declare {t_full} {name}\")\n",
    "        elif label == \"CALL\":\n",
    "            mfn = node.get('METHOD_FULL_NAME', '').strip('\"')\n",
    "            code_short = code.split('(')[0]\n",
    "            # Assignment\n",
    "            if mfn == \"<operator>.assignment\":\n",
    "                trace.append(f\"assign: {code}\")\n",
    "            # Function call\n",
    "            elif not mfn.startswith(\"<operator>\"):\n",
    "                trace.append(f\"call: {mfn} ({code})\")\n",
    "            # Conditional or logical operators\n",
    "            elif mfn in [\"<operator>.conditional\", \"<operator>.logicalNot\", \"<operator>.notEquals\"]:\n",
    "                trace.append(f\"condition: {code}\")\n",
    "            # Field/pointer access\n",
    "            elif mfn == \"<operator>.indirectFieldAccess\":\n",
    "                trace.append(f\"field_access: {code}\")\n",
    "        elif label == \"IDENTIFIER\":\n",
    "            tname = node.get(\"TYPE_FULL_NAME\", \"\")\n",
    "            type_clean = tname.strip('\"')\n",
    "            code_clean = code\n",
    "            trace.append(f\"use {code_clean} as {type_clean}\")\n",
    "        elif label == \"LITERAL\":\n",
    "            trace.append(f\"literal: {code}\")\n",
    "        elif label == \"FIELD_IDENTIFIER\":\n",
    "            field_name = node['CANONICAL_NAME'].strip('\"')\n",
    "            trace.append(f\"field: {field_name}\")\n",
    "\n",
    "        # Add more node type cases as needed.\n",
    "\n",
    "        # Recurse on AST children\n",
    "        for e in edges:\n",
    "            if e['src'] == node_id and e['label'] == '\"AST\"':\n",
    "                walk_ast(e['dst'])\n",
    "\n",
    "    walk_ast(body_id)\n",
    "    return trace\n"
   ],
   "id": "60704bc71e75e1fa",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T17:18:15.092321Z",
     "start_time": "2025-07-06T17:18:15.081100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def extract_event_trace_from_joern(graph_json):\n",
    "    \"\"\"\n",
    "    Extracts a detailed, stepwise event trace from a Joern graph.json file\n",
    "    for a C/C++ function. Designed for conflict-driven learning (CDL),\n",
    "    contrastive neuro-symbolic research, or explainable code analysis.\n",
    "\n",
    "    Args:\n",
    "        graph_json (dict): Loaded Joern graph.json object.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Stepwise event trace, formatted for symbolic learning.\n",
    "    \"\"\"\n",
    "    nodes = {str(n['id']): n for n in graph_json['nodes']}\n",
    "    edges = graph_json['edges']\n",
    "\n",
    "    # Find the main METHOD node (function)\n",
    "    method_nodes = [n for n in nodes.values() if n['label'].strip('\"') == 'METHOD']\n",
    "    if not method_nodes:\n",
    "        raise ValueError(\"No METHOD node found in the graph.\")\n",
    "    method = method_nodes[0]\n",
    "\n",
    "    # Find the AST root for the function body (BLOCK node)\n",
    "    ast_body_edges = [e for e in edges if e['src'] == method['id'] and e['label'] == '\"AST\"']\n",
    "    body_id = None\n",
    "    for e in ast_body_edges:\n",
    "        dst = nodes.get(e['dst'])\n",
    "        if dst and dst['label'].strip('\"') == 'BLOCK':\n",
    "            body_id = dst['id']\n",
    "            break\n",
    "    if not body_id:\n",
    "        raise ValueError(\"No BLOCK node (function body) found in the graph.\")\n",
    "\n",
    "    # Helper to clean field values\n",
    "    def clean(field):\n",
    "        return field.strip('\"') if isinstance(field, str) else str(field)\n",
    "\n",
    "    # Helper to get AST children\n",
    "    def get_ast_children(node_id):\n",
    "        return [e['dst'] for e in edges if e['src'] == node_id and e['label'] == '\"AST\"']\n",
    "\n",
    "    trace = []\n",
    "\n",
    "    def walk_ast(node_id, indent=0):\n",
    "        node = nodes[str(node_id)]\n",
    "        label = node['label'].strip('\"')\n",
    "        code = clean(node.get('CODE', ''))\n",
    "\n",
    "        # --- Variable declarations ---\n",
    "        if label == \"LOCAL\":\n",
    "            trace.append(\"    \" * indent + f\"declare {clean(node['TYPE_FULL_NAME'])} {clean(node['NAME'])}\")\n",
    "\n",
    "        # --- Assignment, calls, field access, operators ---\n",
    "        elif label == \"CALL\":\n",
    "            mfn = clean(node.get('METHOD_FULL_NAME', ''))\n",
    "            if mfn == \"<operator>.assignment\":\n",
    "                trace.append(\"    \" * indent + f\"assign: {code}\")\n",
    "            elif mfn == \"<operator>.indirectFieldAccess\":\n",
    "                trace.append(\"    \" * indent + f\"field_access: {code}\")\n",
    "            elif mfn in [\"<operator>.conditional\", \"<operator>.logicalNot\", \"<operator>.notEquals\", \"<operator>.equals\", \"<operator>.and\", \"<operator>.or\"]:\n",
    "                trace.append(\"    \" * indent + f\"condition: {code}\")\n",
    "            elif mfn.startswith(\"<operator>\"):\n",
    "                trace.append(\"    \" * indent + f\"operator: {mfn} ({code})\")\n",
    "            else:  # Regular function call\n",
    "                trace.append(\"    \" * indent + f\"call: {mfn} ({code})\")\n",
    "\n",
    "        # --- Variable usage ---\n",
    "        elif label == \"IDENTIFIER\":\n",
    "            tname = clean(node.get(\"TYPE_FULL_NAME\", \"\"))\n",
    "            trace.append(\"    \" * indent + f\"use {code} as {tname}\")\n",
    "\n",
    "        # --- Constants/literals ---\n",
    "        elif label == \"LITERAL\":\n",
    "            trace.append(\"    \" * indent + f\"literal: {code}\")\n",
    "\n",
    "        # --- Field identifiers ---\n",
    "        elif label == \"FIELD_IDENTIFIER\":\n",
    "            field_name = clean(node.get('CANONICAL_NAME', ''))\n",
    "            trace.append(\"    \" * indent + f\"field: {field_name}\")\n",
    "\n",
    "        # --- Control structures: if, else, loops, etc ---\n",
    "        elif label == \"CONTROL_STRUCTURE\":\n",
    "            cs_code = code.lower()\n",
    "            children = get_ast_children(node_id)\n",
    "            if cs_code.startswith('if'):\n",
    "                # Try to extract the condition node and then/else blocks\n",
    "                if len(children) >= 2:\n",
    "                    cond_id = children[0]\n",
    "                    then_id = children[1]\n",
    "                    cond_code = nodes[str(cond_id)].get('CODE', '').strip()\n",
    "                    trace.append(\"    \" * indent + f\"if: {cond_code}\")\n",
    "                    walk_ast(then_id, indent + 1)\n",
    "                    # Check for 'else' block\n",
    "                    if len(children) > 2:\n",
    "                        else_id = children[2]\n",
    "                        trace.append(\"    \" * indent + \"else\")\n",
    "                        walk_ast(else_id, indent + 1)\n",
    "                else:\n",
    "                    trace.append(\"    \" * indent + f\"if: {code}\")\n",
    "            elif cs_code.startswith('else if'):\n",
    "                trace.append(\"    \" * indent + f\"else if: {code}\")\n",
    "            elif cs_code.startswith('else'):\n",
    "                trace.append(\"    \" * indent + \"else\")\n",
    "                if children:\n",
    "                    walk_ast(children[0], indent + 1)\n",
    "            elif cs_code.startswith('for'):\n",
    "                trace.append(\"    \" * indent + f\"for: {code}\")\n",
    "                if children:\n",
    "                    walk_ast(children[-1], indent + 1)\n",
    "            elif cs_code.startswith('while'):\n",
    "                trace.append(\"    \" * indent + f\"while: {code}\")\n",
    "                if children:\n",
    "                    walk_ast(children[-1], indent + 1)\n",
    "            elif cs_code.startswith('switch'):\n",
    "                trace.append(\"    \" * indent + f\"switch: {code}\")\n",
    "                if children:\n",
    "                    for cid in children[1:]:\n",
    "                        walk_ast(cid, indent + 1)\n",
    "            elif cs_code.startswith('return'):\n",
    "                trace.append(\"    \" * indent + f\"return: {code}\")\n",
    "            else:\n",
    "                trace.append(\"    \" * indent + f\"control: {code}\")\n",
    "\n",
    "        # --- Return statements ---\n",
    "        elif label == \"RETURN\":\n",
    "            trace.append(\"    \" * indent + f\"return: {code}\")\n",
    "\n",
    "        # --- Recursively process children (except CONTROL_STRUCTURE, which we handled above) ---\n",
    "        if label not in [\"CONTROL_STRUCTURE\"]:\n",
    "            for child_id in get_ast_children(node_id):\n",
    "                walk_ast(child_id, indent)\n",
    "\n",
    "    walk_ast(body_id)\n",
    "    return trace\n"
   ],
   "id": "3fa7c425dc1b60b6",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T17:20:17.228610Z",
     "start_time": "2025-07-06T17:18:39.874105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"devign.csv\")\n",
    "df = df.iloc[:-1]\n",
    "\n",
    "\n",
    "def get_graph_path(idx):\n",
    "    return f\"/mnt/c/Users/user01/PycharmProjects/PythonProject2/joern_outputs/sample_{idx}/json/graph.json\"\n",
    "\n",
    "df[\"graph_path\"] = df.index.map(get_graph_path)\n",
    "\n",
    "df[\"event_trace\"] = df[\"graph_path\"].apply(lambda p: extract_event_trace_from_joern(json.load(open(p))))\n",
    "\n",
    "\n",
    "df.to_csv(\"devign_with_event_trace_graph.csv\", index=False,quoting=1)"
   ],
   "id": "5bd6d1eff2def9d8",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T17:20:20.718688Z",
     "start_time": "2025-07-06T17:20:20.713152Z"
    }
   },
   "cell_type": "code",
   "source": "df['event_trace'].iloc[14000]",
   "id": "4796749b9865249a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['declare uint32_t sctlr',\n",
       " 'assign: sctlr = A32_BANKED_CURRENT_REG_GET(env, sctlr)',\n",
       " 'use sctlr as uint32_t',\n",
       " 'call: A32_BANKED_CURRENT_REG_GET (A32_BANKED_CURRENT_REG_GET(env, sctlr))',\n",
       " 'use env as CPUARMState*',\n",
       " 'use sctlr as uint32_t',\n",
       " 'if: \"address < 0x02000000\"',\n",
       " '    operator: <operator>.assignmentPlus (address += env->cp15.c13_fcse)',\n",
       " '    use address as target_ulong',\n",
       " '    operator: <operator>.fieldAccess (env->cp15.c13_fcse)',\n",
       " '    field_access: env->cp15',\n",
       " '    use env as CPUARMState*',\n",
       " '    field: cp15',\n",
       " '    field: c13_fcse',\n",
       " 'if: \"(sctlr & SCTLR_M) == 0\"',\n",
       " '    assign: *phys_ptr = address',\n",
       " '    operator: <operator>.indirection (*phys_ptr)',\n",
       " '    use phys_ptr as hwaddr*',\n",
       " '    use address as target_ulong',\n",
       " '    assign: *prot = PAGE_READ | PAGE_WRITE | PAGE_EXEC',\n",
       " '    operator: <operator>.indirection (*prot)',\n",
       " '    use prot as int*',\n",
       " '    condition: PAGE_READ | PAGE_WRITE | PAGE_EXEC',\n",
       " '    condition: PAGE_READ | PAGE_WRITE',\n",
       " '    use <unknown> PAGE_READ as ANY',\n",
       " '    use <unknown> PAGE_WRITE as ANY',\n",
       " '    use <unknown> PAGE_EXEC as ANY',\n",
       " '    assign: *page_size = TARGET_PAGE_SIZE',\n",
       " '    operator: <operator>.indirection (*page_size)',\n",
       " '    use page_size as target_ulong*',\n",
       " '    use <unknown> TARGET_PAGE_SIZE as ANY',\n",
       " '    return: return 0;',\n",
       " '    literal: 0',\n",
       " 'else',\n",
       " '    else',\n",
       " '        if: \"arm_feature(env, ARM_FEATURE_MPU)\"',\n",
       " '            assign: *page_size = TARGET_PAGE_SIZE',\n",
       " '            operator: <operator>.indirection (*page_size)',\n",
       " '            use page_size as target_ulong*',\n",
       " '            use <unknown> TARGET_PAGE_SIZE as ANY',\n",
       " '            return: return get_phys_addr_mpu(env, address, access_type, is_user, phys_ptr, prot);',\n",
       " '            call: get_phys_addr_mpu (get_phys_addr_mpu(env, address, access_type, is_user, phys_ptr, prot))',\n",
       " '            use env as CPUARMState*',\n",
       " '            use address as target_ulong',\n",
       " '            use access_type as int',\n",
       " '            use is_user as int',\n",
       " '            use phys_ptr as hwaddr*',\n",
       " '            use prot as int*',\n",
       " '        else',\n",
       " '            else',\n",
       " '                if: \"extended_addresses_enabled(env)\"',\n",
       " '                    return: return get_phys_addr_lpae(env, address, access_type, is_user, phys_ptr, prot, page_size);',\n",
       " '                    call: get_phys_addr_lpae (get_phys_addr_lpae(env, address, access_type, is_user, phys_ptr, prot, page_size))',\n",
       " '                    use env as CPUARMState*',\n",
       " '                    use address as target_ulong',\n",
       " '                    use access_type as int',\n",
       " '                    use is_user as int',\n",
       " '                    use phys_ptr as hwaddr*',\n",
       " '                    use prot as int*',\n",
       " '                    use page_size as target_ulong*',\n",
       " '                else',\n",
       " '                    else',\n",
       " '                        if: \"sctlr & SCTLR_XP\"',\n",
       " '                            return: return get_phys_addr_v6(env, address, access_type, is_user, phys_ptr, prot, page_size);',\n",
       " '                            call: get_phys_addr_v6 (get_phys_addr_v6(env, address, access_type, is_user, phys_ptr, prot, page_size))',\n",
       " '                            use env as CPUARMState*',\n",
       " '                            use address as target_ulong',\n",
       " '                            use access_type as int',\n",
       " '                            use is_user as int',\n",
       " '                            use phys_ptr as hwaddr*',\n",
       " '                            use prot as int*',\n",
       " '                            use page_size as target_ulong*',\n",
       " '                        else',\n",
       " '                            else',\n",
       " '                                return: return get_phys_addr_v5(env, address, access_type, is_user, phys_ptr, prot, page_size);',\n",
       " '                                call: get_phys_addr_v5 (get_phys_addr_v5(env, address, access_type, is_user, phys_ptr, prot, page_size))',\n",
       " '                                use env as CPUARMState*',\n",
       " '                                use address as target_ulong',\n",
       " '                                use access_type as int',\n",
       " '                                use is_user as int',\n",
       " '                                use phys_ptr as hwaddr*',\n",
       " '                                use prot as int*',\n",
       " '                                use page_size as target_ulong*',\n",
       " 'declare ANY SCTLR_XP',\n",
       " 'declare ANY TARGET_PAGE_SIZE',\n",
       " 'declare ANY ARM_FEATURE_MPU',\n",
       " 'declare ANY PAGE_EXEC',\n",
       " 'declare ANY PAGE_WRITE',\n",
       " 'declare ANY PAGE_READ',\n",
       " 'declare ANY SCTLR_M']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fine-tune",
   "id": "bf0a4390c7158d04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:49:32.468086Z",
     "start_time": "2025-07-06T23:49:32.274295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def build_input(row):\n",
    "    trace_str = \"; \".join(row['event_trace']) if isinstance(row['event_trace'], list) else str(row['event_trace'])\n",
    "    return row['func'] + \" [SEP] \" + trace_str\n",
    "\n",
    "df['input'] = df.apply(build_input, axis=1)\n"
   ],
   "id": "c6045facd4e193a3",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:52:28.887203Z",
     "start_time": "2025-07-06T23:52:23.193659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['target'])\n",
    "\n",
    "\n",
    "train_df.to_csv(\"cdl_train.csv\", index=False)\n",
    "test_df.to_csv(\"cdl_test.csv\", index=False)\n",
    "\n"
   ],
   "id": "5a69063217201fdd",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:56:00.461986Z",
     "start_time": "2025-07-06T23:55:54.670721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = df.rename(columns={\"target\": \"label\"})\n",
    "# Split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "# Save splits\n",
    "train_df.to_csv(\"cdl_train.csv\", index=False)\n",
    "test_df.to_csv(\"cdl_test.csv\", index=False)\n",
    "\n",
    "\n"
   ],
   "id": "d390711548c7e190",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T02:22:38.837466Z",
     "start_time": "2025-07-07T02:22:38.826109Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.info()",
   "id": "eef27272177815cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11224 entries, 0 to 11223\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   func          11224 non-null  object\n",
      " 1   func_cleaned  11224 non-null  object\n",
      " 2   project       11224 non-null  object\n",
      " 3   label         11224 non-null  int64 \n",
      " 4   graph_path    11224 non-null  object\n",
      " 5   event_trace   11224 non-null  object\n",
      " 6   input         11224 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 613.9+ KB\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T02:22:22.871334Z",
     "start_time": "2025-07-07T02:22:22.842314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "test_df.info()"
   ],
   "id": "4977118bd5545aa9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11224 entries, 0 to 11223\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   func          11224 non-null  object\n",
      " 1   func_cleaned  11224 non-null  object\n",
      " 2   project       11224 non-null  object\n",
      " 3   label         11224 non-null  int64 \n",
      " 4   graph_path    11224 non-null  object\n",
      " 5   event_trace   11224 non-null  object\n",
      " 6   input         11224 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 613.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2807 entries, 0 to 2806\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   func          2807 non-null   object\n",
      " 1   func_cleaned  2807 non-null   object\n",
      " 2   project       2807 non-null   object\n",
      " 3   label         2807 non-null   int64 \n",
      " 4   graph_path    2807 non-null   object\n",
      " 5   event_trace   2807 non-null   object\n",
      " 6   input         2807 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 153.6+ KB\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T02:00:52.102121Z",
     "start_time": "2025-07-07T01:41:52.130193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "# Load splits\n",
    "train_df = pd.read_csv(\"cdl_train.csv\")\n",
    "test_df = pd.read_csv(\"cdl_test.csv\")\n",
    "# Before creating the HuggingFace Dataset\n",
    "train_df['label'] = train_df['label'].astype(int)\n",
    "test_df['label'] = test_df['label'].astype(int)\n",
    "\n",
    "# Use input and label columns\n",
    "hf_train = Dataset.from_pandas(train_df[['input', 'label']])\n",
    "hf_test = Dataset.from_pandas(test_df[['input', 'label']])\n",
    "\n",
    "# Use CodeBERT (recommended for code classification)\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"input\"], truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "tokenized_train = hf_train.map(tokenize_function, batched=True)\n",
    "tokenized_test = hf_test.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()[:, 1]\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    return {\n",
    "        \"accuracy\":    accuracy_score(labels, preds),\n",
    "        \"precision\":   precision_score(labels, preds, zero_division=0),\n",
    "        \"recall\":      recall_score(labels, preds, zero_division=0),\n",
    "        \"specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        \"fpr\":         fp / (fp + tn) if (fp + tn) > 0 else 0,\n",
    "        \"f1\":          f1_score(labels, preds, zero_division=0),\n",
    "        \"mcc\":         matthews_corrcoef(labels, preds),\n",
    "        \"kappa\":       cohen_kappa_score(labels, preds),\n",
    "        \"mse\":         mean_squared_error(labels, preds),\n",
    "        \"mae\":         mean_absolute_error(labels, preds),\n",
    "        \"auc\":         auc\n",
    "    }\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./cdl_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",  # <-- must match key in your compute_metrics dict!\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,   # <-- this is the key part!\n",
    ")\n",
    "trainer.train()\n"
   ],
   "id": "dad80bfebd7b0d28",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11224/11224 [00:08<00:00, 1313.96 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2807/2807 [00:01<00:00, 1450.38 examples/s]\n",
      "/home/shaon/.virtualenvs/PythonProject2/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_2344918/3099616603.py:77: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8418' max='8418' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8418/8418 18:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Fpr</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.721600</td>\n",
       "      <td>0.684710</td>\n",
       "      <td>0.572497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>0.482588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.682603</td>\n",
       "      <td>0.572497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>0.487289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.682873</td>\n",
       "      <td>0.572497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>0.427503</td>\n",
       "      <td>0.484980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8418, training_loss=0.6882378701558728, metrics={'train_runtime': 1124.8673, 'train_samples_per_second': 29.934, 'train_steps_per_second': 7.484, 'total_flos': 4429737728040960.0, 'train_loss': 0.6882378701558728, 'epoch': 3.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T03:15:18.231546Z",
     "start_time": "2025-07-07T03:15:12.747968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, matthews_corrcoef,\n",
    "    cohen_kappa_score, mean_squared_error,\n",
    "    mean_absolute_error, roc_auc_score\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "# Load splits\n",
    "train_df = pd.read_csv(\"cdl_train.csv\")\n",
    "test_df = pd.read_csv(\"cdl_test.csv\")\n",
    "# Before creating the HuggingFace Dataset\n",
    "train_df['label'] = train_df['label'].astype(int)\n",
    "test_df['label'] = test_df['label'].astype(int)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "# Optionally reduce dataset for quick test\n",
    "# train_df = train_df.sample(500)\n",
    "# test_df = test_df.sample(100)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['input', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['input', 'label']])"
   ],
   "id": "122749cf4104c8d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T03:17:12.692638Z",
     "start_time": "2025-07-07T03:17:11.530297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_example(example):\n",
    "    # Format as prompt and response, for each example\n",
    "    return {\n",
    "        \"prompt\": f\"<s>Code:\\n{example['input']}\\nLabel:\",\n",
    "        \"completion\": f\" {example['label']}</s>\"\n",
    "    }\n",
    "\n",
    "train_dataset = train_dataset.map(format_example)\n",
    "test_dataset = test_dataset.map(format_example)\n"
   ],
   "id": "35368a42a6a197f3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11224/11224 [00:00<00:00, 11772.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2807/2807 [00:00<00:00, 15612.53 examples/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Conflict",
   "id": "6fa105abc575f451"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T23:44:04.159946Z",
     "start_time": "2025-07-06T23:44:04.152396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def identify_conflicts(event_trace, predicted_label):\n",
    "    \"\"\"\n",
    "    Given an event trace (list of symbolic actions) and the model's predicted label,\n",
    "    return (conflict: bool, reasons: list of explanations).\n",
    "    \"\"\"\n",
    "    reasons = []\n",
    "    conflict = False\n",
    "\n",
    "    # Unsafe pointer assignment with no prior check\n",
    "    for i, event in enumerate(event_trace):\n",
    "        if event.startswith(\"assign: *\"):\n",
    "            # Look back for any if/condition/guard in the last few events\n",
    "            guarded = any(event_trace[j].startswith('if:') or 'check' in event_trace[j]\n",
    "                          for j in range(max(0, i-5), i))\n",
    "            if not guarded and predicted_label == 0:\n",
    "                conflict = True\n",
    "                reasons.append(f\"Unsafe pointer assignment '{event}' not preceded by a safety check, but model predicted not vulnerable.\")\n",
    "\n",
    "    # Use of <unknown> types/constants\n",
    "    for event in event_trace:\n",
    "        if 'use <unknown>' in event and predicted_label == 0:\n",
    "            conflict = True\n",
    "            reasons.append(f\"Use of unknown/untrusted type in '{event}' but model predicted not vulnerable.\")\n",
    "\n",
    "    # Direct field access without checks\n",
    "    for event in event_trace:\n",
    "        if \"field_access\" in event and predicted_label == 0:\n",
    "            conflict = True\n",
    "            reasons.append(f\"Direct field access '{event}' could be unsafe, but model predicted not vulnerable.\")\n",
    "\n",
    "    # Return after unsafe op\n",
    "    for i, event in enumerate(event_trace):\n",
    "        if event.startswith(\"return:\") and predicted_label == 0:\n",
    "            # Check for unsafe ops in the previous few events\n",
    "            unsafe_ops = any(\"assign: *\" in e for e in event_trace[max(0, i-5):i])\n",
    "            if unsafe_ops:\n",
    "                conflict = True\n",
    "                reasons.append(f\"Returning after unsafe op before '{event}', but model predicted not vulnerable.\")\n",
    "\n",
    "    # Unsafe operation inside an else branch\n",
    "    for i, event in enumerate(event_trace):\n",
    "        if event == \"else\" and predicted_label == 0:\n",
    "            possible_unsafe = any(\"assign: *\" in e for e in event_trace[i:i+5])\n",
    "            if possible_unsafe:\n",
    "                conflict = True\n",
    "                reasons.append(\"Possible unsafe write in else-branch, but model predicted not vulnerable.\")\n",
    "\n",
    "    return conflict, reasons\n",
    "\n",
    "\n"
   ],
   "id": "ce81667c295edd2a",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def conflict_wrapper(row):\n",
    "    conflict, reasons = identify_conflicts(row['event_trace'], row['predicted_label'])\n",
    "    return pd.Series({\n",
    "        \"conflict\": conflict,\n",
    "        \"conflict_reasons\": reasons\n",
    "    })\n",
    "\n",
    "df[['conflict', 'conflict_reasons']] = df.apply(conflict_wrapper, axis=1)\n"
   ],
   "id": "9f47e209f920177a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
